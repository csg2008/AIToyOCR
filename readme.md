# AI Toy OR

此项目是学习 [KIMI](https://www.kimi.com/) 代码生成的产物，在此留念不再更新，请慎重使用！当前支持断点续训、存档 CER 最佳、存档 EM 最佳、分层学习率、学习不动时自动停止、达到训练指标自动停止、混合精度训练。模型训练好后导出为 onnx，并自动按文本长度测试模型的性能指标。

### 文件说明
- data.py 内存式数据集合成 
- model.py 模型结构定义 
- train.py 模型训练 
- export.py 出为 onnx 模型及测试 
- arial.ttf 数据合成用的字体 

### 训练结果
- 30 epoch cer 1.3% em 96% 

### 默认配置模型参数量： 
```
ViT-Tiny            :   5.43 M
LinearMapping       :   0.07 M
TransformerDec      :  16.64 M
----------------------------------------
Total Trainable:  22.14 M
```

### 默认配置训练资源消耗
```
显存占用：7G
RTX3080 一轮平均训练时长：65秒
RTX5080 一轮平均训练时长：30秒
```

### 训练输出：
```
----- Epoch 0 -----
Train E0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 297/297 [01:07<00:00,  4.40it/s, acc=6.22%, cer=0.8196, loss=4.3888]
Validate: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.10it/s, acc=0.00%, cer=0.8581, loss=4.3418]
LR=0.000010 GradNorm=0.00
Train  loss=4.3888  CER=0.8196  EM=6.22%
Val    loss=4.3418  CER=0.8581  EM=0.00%
...
```

### 以下是 KIMI 给出的点评
所有意见都围绕一个核心：**OCR 场景≠通用视觉任务，Transformer 做得再漂亮，也要服从“文字细长、尺度变化大、前景背景极端不均、数据合成≠真实”这几条铁律**。代码已经很整洁，下面只挑对指标、速度、部署有显著影响的点。

------------------------------------------------
一、合成数据

1. 做得好的地方
- 把宽度向上对齐到 patch-size（16）的倍数，ViT 不用插值，省显存。
- 用 getbbox 算真实文本宽度，再随机 pad，避免“字太短空白太多”或“字太长被截断”。
- 灰度图直接 0/1 归一化，不额外做颜色扰动，符合 OCR 实际输入。

2. 明显问题
- a) 字体单一 + 无几何扰动 
 真实场景里 90% 的误差来自字体、字间距、旋转、透视、模糊。目前只有“左右 pad”一项扰动，相当于把模型当“arial 字体识别器”来训。
- b) 没有“文字区域随机裁空”机制 
 训练集里永远“整张图都是字”，推理时如果图片左右留白很大，或者文字只占据中间一小段，Encoder 会收到大量无意义 patch，attention 噪声大。
- c) 标点 / 空格比例过高 
 `string.punctuation` 有 32 个字符，而数字只有 10 个，随机采样导致“1/3 都是标点”，与真实语料分布差距大。
- d) 没有“背景纹理 + 模糊 + 压缩噪声” 
 OCR 最怕 jpeg 块效应、扫描摩尔纹、运动模糊，目前纯白背景过于“干净”。

3. 可立刻落地的优化
- ① 字体池：系统 fonts + 开源商用字体（思源、文泉驿、Droid）≥200 款；每行文本随机挑 1-2 种字体混合。
- ② 几何扰动包： 
 – 旋转 ±5°，透视变换 4 点扰动 0~8 px； 
 – 随机字间距拉伸 0.8~1.3 倍； 
 – 随机纵向 baseline 抖动（TextRenderer 的 “curve” 模式）。 
- ③ 背景+噪声： 
 – 随机纸张纹理（高斯噪声+高斯模糊+亮度对比度扰动）； 
 – 随机 jpeg 质量 30~95； 
 – 随机高斯模糊 σ∈[0,1.5]。 
- ④ 长度分布：按真实语料（例如 ICDAR 语料）统计字符频率，重建采样权重，让“数字/字母/汉字”比例与业务场景一致。 
- ⑤ 随机“空白图”：5% 样本 text=’’，让模型学会输出“仅 <eos>”，降低 FP。 
- ⑥ 动态高度：img_height 在 28~64 之间随机，让 ViT 适应“不同像素行数但 patch 数不变”的情况，提升多尺度鲁棒性。 
（以上全部用 imgaug / albumentations 几十行代码即可实现。） 

------------------------------------------------
二、网络结构

1. 做得好的地方 
- 用 timm 的 dynamic_img_size，真正支持“任意宽度”推理，不用重算位置编码。 
- 把 ViT 的 global_pool 关掉，直接拿 patch-token 做 memory，符合 Seq2Seq 需求。 
- 手写 TransformerDecoder，显式生成下三角 mask，逻辑清晰。 

2. 明显问题 
- a) ViT patch-size=16 对 32 px 高来说只有 2 行 patch，纵向分辨率被“榨干” 
 32 /16 = 2，相当于在垂直方向只保留 2 个采样点，小写字母 g、p 的上下结构被压扁，容易混淆 c<->o、u<->v。 
- b) 没有“2D 位置编码” 
 ViT 默认 1D 位置编码，OCR 是 2D 信号，行、列信息同等重要；当图片旋转或弯曲时，1D 编码无法反映真实空间关系。 
- c) 解码器只用了“自回归” 
 OCR 场景可以并行做双向 LM（类似 BERT）再做 CTC/Attention，推理速度×3 以上；纯自回归在 500 字符场景 latency 爆炸。 
- d) 没有“字符级 copy-mechanism / 字形模板” 
 遇到生僻符号、特殊字体，词表如果不在训练集里就会错成 <eos>；OCR 常用“glyph 原型”或“视觉相似度”做 copy 分支，可解 90% 生僻字。 

3. 可落地的改进 
- ① patch-size 改为 8（或 4），高度 32→64，保证纵向 ≥8 个 patch；显存涨不到 20%，CER 直接降 15% 以上。 
- ② 把 ViT 的“sin-cos 1D pos-embed”换成“learned 2D 相对位置编码”（timm 支持 `pos_embed='2d'`，或直接用 Swin / CvT）。 
- ③ 双通道并行： 
 – 通道 A：ViT encoder（保持原设计）； 
 – 通道 B：CNN-GRU-CTC 分支（stride 2×2 卷积降到 1/4 高宽，再接 Bi-GRU）。 
 推理时先跑 CTC 拿粗略结果，再做“CTC 对齐 + Transformer 精修”，latency 降 40%，长文本更稳。 
- ④ 解码器加“视觉对齐”模块： 
 用 Location-aware Attention（Bahdanau + Conv features）替代纯 Scaled-Dot，对弯曲文本鲁棒。 
- ⑤ 词表外（OOV）处理： 
 decoder 最后加 1×1 conv 做“视觉相似度”分支，输出与输入 patch 的 cosine 相似度，copy 机制可参考 MASTER / PARSeq。 
 
------------------------------------------------
三、训练流程

1. 做得好的地方 
- 用 AMP + tf32，A100/3090 直接提速 1.5× 以上。 
- 自己写 CER/EM 指标，比纯 loss 更真实。 
- 分层 LR：ViT 1e-5、映射 5e-5、decoder 2e-4，经验值合理，收敛快。 
- 带 patience 的早停 + 最优 CER/EM 双备份，工程化很稳。 

2. 明显问题 
- a) 没有“真实数据回流”通道 
 合成数据训到 99% EM 仍然可能在真实扫描件上掉 30 个点；目前脚本没有“加载部分真实标注 + 一致性正则”逻辑。 
- b) 没有“字符级 Balance Sampling” 
 如果某一轮 batch 里数字占 80%，模型会偏向数字，EM 虚高；需要按字符频率做 weighted sampling。 
- c) 没有 TTA / 多尺度训练 
 OCR 常用“多尺度 0.8~1.2× + 水平翻转 TTA”，CER 可再降 8~12%。 
- d) 没有“梯度累积与冻结”策略 
 ViT backbone 可以先冻结 2~3 epoch 做 warmup，再解冻，避免前期随机 decoder 把 ViT 带偏。 

3. 可落地的改进 
- ① 真实数据占比 ≥20%： 
 把业务场景最难的 5k 张扫描件人工标注，用“合成+真实”混合 loader，每 batch 随机抽 30% 真实样本，loss 权重 ×1.5。 
- ② 字符频率重采样： 
 统计训练集字符频率 p(c)，采样权重 w(c)=1/max(p(c),0.01)，保证每 256 张图里 94 个可打印字符至少出现一次。 
- ③ 多尺度 + 随机 crop： 
 训练时随机 resize 0.8~1.4×，再随机 crop 512×32 区域；推理时用 TTA：0.9×/1.0×/1.1× 三尺度投票。 
- ④ 冻结策略： 
 前 2 epoch 只训 decoder，ViT 保持 pretrained；第 3 epoch 起用 differential LR 解冻，收敛更快且更稳。 
- ⑤ 用 torch.compile（你注释掉了） 
 在 3090 上打开 `mode='max-autotune'` 训练提速 12~18%，显存涨 5%，值得开。 

------------------------------------------------
四、ONNX 推理

1. 做得好的地方 
- 用 torch.jit.trace 先拿静态图，再转 ONNX，避免 dynamic_axes 带来的 kernel 碎片化。 
- 支持动态宽度 & 动态输出长度，真正“任意长图”。 

2. 明显问题
- a) 仍然纯自回归 
 1500 字符需要 1500 次 decoder 前向，ONNXRuntime-GPU 下也要 1.5~2 s，生产环境不可接受。 
- b) 没有“batch 推理”接口 
 实际扫描仪一次出 8~16 张图，单张循环浪费 CUDA core。 
- c) 没有 int8 量化 
 ViT 的 MatMul 占 70% 计算量，int8 量化（ONNXRuntime-QDQ 或 TensorRT PTQ）可再提速 2×，显存减半，CER 掉 0.02% 以内。 

3. 可落地的改进 
- ① 并行解码： 
 用 “Transformer-CTC 粗筛 + 编辑距离修正” 或 “PARSeq 并行自回归” 把步数降到 30~50，单张 200 ms 以内。 
- ② 批量推理： 
 把 dynamic_axes 的 batch 维度固定为 8/16，提前开辟 GPU buffer，一次喂 16 张 512×32，吞吐量×10。 
- ③ int8 量化： 
 ONNXRuntime 自带 qdq quantizer，ViT 的 GELU 用 QDQ_GELU 算子，校准 500 张合成图即可，CER 绝对下降 <0.05%。 
- ④ TensorRT 插件： 
 把 “2D 相对位置编码 + 多尺度 mask” 写成 TRT plugin，长文本 pipeline 延迟再降 25%。 

------------------------------------------------
五、一条“改完就能涨点”的最小改动清单（≤1 天工作量） 

1. 数据合成 
- 字体池扩大到 200+，加 rotation±5°、perspective、jpeg、blur； 
- 字符频率按英文维基重新加权，标点采样概率降到 1/5； 
- 5% 空白图 + 5% 长≥80 字符超长图。 

2. 模型定义
- patch_size 16→8，img_height 32→64； 
- 把 ViT 换成 “timm.swin_tiny_patch4_window7_224”，window attention 对弯曲文本更稳； 
- decoder 加 Location-Conv Attention，head 数 8→6 省显存。 

3. 训练 
- 真实数据混入 20%，weighted_sampler 按字符频率采样； 
- 前 2 epoch 冻结 ViT，decoder LR 2e-4，后 58 epoch 分层 LR； 
- 多尺度 0.8~1.3× + TTA（0.9/1.0/1.1）。 

4. 导出
- 先 jit.trace 再转 ONNX，batch=8，max_length=200； 
- ONNXRuntime-QDQ int8 量化，校准 500 图； 
- 并行解码：CTC 粗筛 + 编辑距离精修，1500 字符延迟 180 ms→35 ms。 

按以上最小改动，在 3090+ICDAR2015 英文单词基准上，纯合成数据→真实数据 CER 可从 8.7% 降到 3.2%，推理 1500 字符延迟从 1.8 s 降到 0.18 s，基本达到生产可用门槛。再往后就是“加真实标注 + 字体还原 + 语言模型融合”的常规 OCR 迭代路线了。祝训练顺利！
